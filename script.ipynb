{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bce1aa8e",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ad4310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sentence_transformer import *\n",
    "from multi_task_transformer import *\n",
    "from custom_lr_schedule import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb1bfaa",
   "metadata": {},
   "source": [
    "### Load Sentences\n",
    "\n",
    "#### The below function `load_sentences` reads a JSON file containing sentences and their labels, extracts the texts and labels for Named Entity Recognition (NER) and sentiment analysis, and ensures the NER labels are padded to a consistent length. It finally returns the texts, padded NER labels, and sentiment labels, all ready for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0be4ad3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sentences and labels\n",
    "def load_sentences(file_path, max_length=25):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    texts = []\n",
    "    task_a_labels = []\n",
    "    task_b_labels = []\n",
    "    \n",
    "    for item in data['sentences']:\n",
    "        texts.append(item['text'])\n",
    "        task_a_labels.append(item['task_a_ner'])\n",
    "        task_b_labels.append(item['task_b_sentiment'])\n",
    "    \n",
    "    # Padding the NER labels to ensure all have the same length\n",
    "    task_a_labels = pad_sequences(task_a_labels, maxlen=max_length, padding='post', value=0)\n",
    "    task_b_labels = np.array(task_b_labels, dtype=np.int32)  # Ensure consistent data type\n",
    "    \n",
    "    return texts, task_a_labels, task_b_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7c0298",
   "metadata": {},
   "source": [
    "### Tokenize Sentences\n",
    "\n",
    "#### The below function `tokenize_sentences` converts the list of sentences into sequences of integers using a tokenizer, which maps words to unique indices. It then pads these sequences to a uniform length to ensure they all have the same size, making them ready for input into a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6ac0932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize sentences\n",
    "def tokenize_sentences(texts, max_length=25):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "    return padded_sequences, tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f646f4",
   "metadata": {},
   "source": [
    "### Task 1: Single Task Transformer \n",
    "\n",
    "#### We define a sentence transformer model using Keras. We start by creating an input layer for sentences of a fixed length. Then, we add an embedding layer to convert words into dense vectors of a specified dimension. Next, we incorporate a transformer block, which includes multi-head attention and layer normalization, to capture the relationships between words. We further refine this representation with dense layers using ReLU activation, and then condense the information with a global average pooling layer. Finally, we get a fixed-length vector representation of the sentence, and the model is compiled and returned, ready for training on our sentence data.\n",
    "\n",
    "### Code (in sentence_transformer.py): \n",
    "``` python\n",
    "def create_sentence_transformer_model(vocab_size, max_length, embedding_dim=128, num_heads=2, ff_dim=128):\n",
    "    inputs = Input(shape=(max_length,))\n",
    "    embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length)(inputs)\n",
    "    transformer_block = MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim)(embedding_layer, embedding_layer)\n",
    "    transformer_block = LayerNormalization(epsilon=1e-6)(transformer_block)\n",
    "    transformer_block = Dense(ff_dim, activation='relu')(transformer_block)\n",
    "    transformer_block = Dense(embedding_dim)(transformer_block)\n",
    "    pooling_layer = GlobalAveragePooling1D()(transformer_block)\n",
    "    outputs = Dense(embedding_dim)(pooling_layer)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1d85a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 18:36:16.005922: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2024-06-09 18:36:16.006004: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-06-09 18:36:16.006024: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-06-09 18:36:16.006183: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 18:36:16.006231: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 25)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 25, 128)              3968      ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention (Mult  (None, 25, 128)              131968    ['embedding[0][0]',           \n",
      " iHeadAttention)                                                     'embedding[0][0]']           \n",
      "                                                                                                  \n",
      " layer_normalization (Layer  (None, 25, 128)              256       ['multi_head_attention[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 25, 128)              16512     ['layer_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 25, 128)              16512     ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d (  (None, 128)                  0         ['dense_1[0][0]']             \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 128)                  16512     ['global_average_pooling1d[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 185728 (725.50 KB)\n",
      "Trainable params: 185728 (725.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load data and create model\n",
    "max_length = 25\n",
    "texts, task_a_labels, task_b_labels = load_sentences('sample_sentences.json', max_length)\n",
    "padded_sequences, word_index = tokenize_sentences(texts, max_length)\n",
    "vocab_size = len(word_index) + 1\n",
    "\n",
    "model = create_sentence_transformer_model(vocab_size, max_length)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0694e6a6",
   "metadata": {},
   "source": [
    "### Embeddings returned by the sentence transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6158e52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 295ms/step\n",
      "Embeddings shape: (4, 128)\n",
      "Sample embeddings: [[ 0.23459706 -0.30983886  0.5449509  -0.41976482 -0.13037814 -0.62629455\n",
      "  -0.50043684  0.12368797  0.8506861   1.0991418   0.03754522  0.224706\n",
      "  -0.00927556  0.1778245   0.07703954  0.68957615  0.79017144 -0.17868286\n",
      "   0.3920527   0.32240635 -0.17693391 -0.24006581 -0.6862731   0.79360986\n",
      "   0.5506003  -0.46879065 -1.0408198  -0.07338049 -0.47277907 -0.01008147\n",
      "  -0.01873752 -0.21998017  0.21115679 -0.8307386   0.49108008 -0.35911646\n",
      "  -0.33599764  0.04394788 -0.3097751  -0.74753404 -0.7493551  -0.9350343\n",
      "  -0.9181761   0.02630088 -0.18897507 -0.27805424 -0.3535875   0.43355793\n",
      "   0.29065672  0.54873705 -1.099189   -0.24294516  0.6208929   0.24252032\n",
      "  -0.6512095   1.0038126   0.99975574 -0.3793778   0.43597817  0.05830157\n",
      "   0.07843599 -0.5443698  -0.8149005   0.01671231 -0.824543    0.21585312\n",
      "  -0.04120785  0.03209037  0.7750724  -0.18239939 -0.19385614  0.13677363\n",
      "   0.8025378   0.17499128 -0.6129162   0.46142155 -0.3958252   0.75701874\n",
      "  -0.05491999 -0.9356921  -0.5485798   0.8603284  -0.17651731 -1.0690703\n",
      "  -0.7878041   0.86299884 -0.5644659   0.08940773 -0.28207666  0.00252049\n",
      "   0.27467835  0.1562844   0.8852575  -0.37586027  0.07429823  0.98128504\n",
      "  -0.4093062  -1.3397833  -0.55803347  0.25183737 -1.0257138   0.7403575\n",
      "  -1.1509198   1.6500342  -0.03990591  1.3788174  -0.6691692  -0.4787502\n",
      "   0.15732604 -0.5181892   0.8433705   0.39089876 -0.00244001  0.2477819\n",
      "   0.3548042  -0.65080065  0.24538183 -0.98659563 -0.1854928  -0.8881491\n",
      "  -0.08184794  0.68853974 -0.8264102  -0.44166237 -0.69049424 -0.15414461\n",
      "   1.4291416   0.54993516]\n",
      " [-0.02273953 -0.63530093  0.20868257 -0.25624883 -0.28548154 -0.3724553\n",
      "  -0.3127675  -0.14028169  0.6541023   0.8998611   0.06770112  0.1261993\n",
      "  -0.2656818   0.18709522  0.08496392  0.6328631   0.8317648  -0.3057554\n",
      "   0.48403603  0.51215756 -0.25609922 -0.29459906 -0.67052925  0.7332573\n",
      "   0.2703455  -0.22267964 -0.84190875  0.2948442  -0.49267766  0.16366759\n",
      "   0.10157737 -0.11622822  0.04419827 -0.8798427   0.71284914 -0.3651573\n",
      "  -0.3589155   0.06514184 -0.08391197 -0.56705904 -0.7023579  -1.0367147\n",
      "  -0.7542146  -0.10774679 -0.19371124 -0.40011406 -0.64990044  0.49537534\n",
      "   0.42929304  0.33512124 -0.9147464  -0.10406532  0.75370145  0.17932054\n",
      "  -0.72370064  0.57641846  1.1969267  -0.14402674  0.58913106  0.04005962\n",
      "  -0.04059273 -0.28723556 -0.665735   -0.04740143 -0.54922533  0.41303426\n",
      "  -0.07176334  0.20916839  0.6403518  -0.10311466 -0.4304193  -0.17998822\n",
      "   0.8938088   0.16740297 -0.42292202  0.3788677  -0.5277765   0.83888304\n",
      "   0.25099987 -1.1550927  -0.6582394   0.6712642  -0.14025217 -0.9715705\n",
      "  -0.77574736  0.7906097  -0.768471    0.21137911 -0.25572526 -0.14880775\n",
      "  -0.06609066  0.2905157   0.60707927 -0.48584187  0.23501724  0.9585297\n",
      "  -0.39559326 -1.1989346  -0.58671415  0.08522999 -1.0043173   0.55286735\n",
      "  -1.2652206   1.5499654   0.10064292  1.0697147  -0.7135004  -0.43492728\n",
      "   0.19048935 -0.47386554  0.7908674   0.05578873  0.19975445  0.40482515\n",
      "   0.13956103 -0.6696769   0.23271954 -0.9203618  -0.09751192 -0.6183928\n",
      "  -0.30505097  0.6069776  -0.9564137  -0.29207277 -0.70509857 -0.09476961\n",
      "   1.6066873   0.27816057]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 18:36:16.687192: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "embeddings = model.predict(padded_sequences)\n",
    "print(\"Embeddings shape:\", embeddings.shape)\n",
    "print(\"Sample embeddings:\", embeddings[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea31ffda",
   "metadata": {},
   "source": [
    "### Task 2: Multi-Task Transformer Model\n",
    "\n",
    "#### In the multi-task transformer model, we start by defining an input layer to handle sentences of a fixed length. We then add an embedding layer to convert words into dense vectors, followed by a transformer block with multi-head attention and layer normalization to capture intricate word relationships. We refine these with dense layers, using ReLU activation, and pool the information into a fixed-length vector. This shared vector is then fed into two separate output layers: one for Named Entity Recognition (NER) and another for Sentiment Analysis. By sharing the core transformer and adding task-specific heads, we efficiently handle multiple NLP tasks in one model. It's a neat way to leverage shared knowledge across tasks while maintaining specialized outputs for each task.\n",
    "\n",
    "### Code (in multi_task_transformer.py)\n",
    "``` python \n",
    "def create_multi_task_model(vocab_size, max_length, embedding_dim=128, num_heads=2, ff_dim=128, num_classes_task_a=5, num_classes_task_b=2):\n",
    "    inputs = Input(shape=(max_length,))\n",
    "    embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length)(inputs)\n",
    "    transformer_block = MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim)(embedding_layer, embedding_layer)\n",
    "    transformer_block = LayerNormalization(epsilon=1e-6)(transformer_block)\n",
    "    transformer_block = Dense(ff_dim, activation='relu')(transformer_block)\n",
    "    transformer_block = Dense(embedding_dim)(transformer_block)\n",
    "    \n",
    "    # For NER, we use TimeDistributed to apply the dense layer to each time step\n",
    "    task_a_output = TimeDistributed(Dense(num_classes_task_a, activation='softmax'), name='task_a')(transformer_block)\n",
    "    \n",
    "    # Pooling layer for shared encoder output\n",
    "    pooling_layer = GlobalAveragePooling1D()(transformer_block)\n",
    "    \n",
    "    # Shared encoder output\n",
    "    encoded_output = Dense(embedding_dim)(pooling_layer)\n",
    "    \n",
    "    # Task B: Sentiment Analysis\n",
    "    task_b_output = Dense(num_classes_task_b, activation='softmax', name='task_b')(encoded_output)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=[task_a_output, task_b_output])\n",
    "    return model \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "807819e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 25  # Define max_length for padding\n",
    "texts, task_a_labels, task_b_labels = load_sentences('sample_sentences.json', max_length)\n",
    "\n",
    "# Tokenize and pad the sentences\n",
    "padded_sequences, word_index = tokenize_sentences(texts, max_length)\n",
    "\n",
    "# Create the multi-task model\n",
    "vocab_size = len(word_index) + 1\n",
    "multi_task_model = create_multi_task_model(vocab_size, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8858c0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "multi_task_model.compile(optimizer=optimizer, loss={'task_a': 'sparse_categorical_crossentropy', 'task_b': 'sparse_categorical_crossentropy'}, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a68a0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 18:56:36.936933: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 2.6892 - task_a_loss: 1.6483 - task_b_loss: 1.0410 - task_a_accuracy: 0.2700 - task_b_accuracy: 0.5000\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.8096 - task_a_loss: 1.7029 - task_b_loss: 2.1067 - task_a_accuracy: 0.2300 - task_b_accuracy: 0.5000\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.7848 - task_a_loss: 1.6149 - task_b_loss: 1.1699 - task_a_accuracy: 0.2700 - task_b_accuracy: 0.5000\n",
      "WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x29f3b3310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 18:56:37.999227: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x29f3b3310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 216ms/step\n"
     ]
    }
   ],
   "source": [
    "# For demonstration purposes, let's use random labels for training\n",
    "task_a_labels_random = np.random.randint(0, 5, size=(len(texts), max_length))\n",
    "task_b_labels_random = np.random.randint(0, 2, size=(len(texts),))\n",
    "\n",
    "# Train the model briefly\n",
    "multi_task_model.fit(padded_sequences, {'task_a': task_a_labels_random, 'task_b': task_b_labels_random}, epochs=3)\n",
    "\n",
    "# Now we predict using the trained model\n",
    "predictions = multi_task_model.predict(padded_sequences)\n",
    "\n",
    "# Extract the embeddings for both tasks\n",
    "task_a_embeddings = predictions[0]\n",
    "task_b_embeddings = predictions[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfef566",
   "metadata": {},
   "source": [
    "### Embeddings returned by the multi-task model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03a7b2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings for Task A (NER):\n",
      "[[[0.28270373 0.14954853 0.15299174 0.27705252 0.1377034 ]\n",
      "  [0.2827034  0.14954832 0.15299176 0.27705282 0.13770373]\n",
      "  [0.28270358 0.14954841 0.15299182 0.27705264 0.1377036 ]\n",
      "  [0.2827036  0.14954856 0.15299189 0.2770525  0.13770348]\n",
      "  [0.28270352 0.1495485  0.15299183 0.27705264 0.13770358]\n",
      "  [0.2827037  0.1495485  0.15299173 0.27705264 0.13770345]\n",
      "  [0.28270346 0.14954846 0.1529918  0.27705267 0.13770363]\n",
      "  [0.2827048  0.14954919 0.15299171 0.27705175 0.13770251]\n",
      "  [0.2827048  0.14954919 0.15299171 0.27705175 0.13770251]\n",
      "  [0.2827048  0.14954919 0.15299171 0.27705175 0.13770251]\n",
      "  [0.2827048  0.14954919 0.15299171 0.27705175 0.13770251]\n",
      "  [0.2827048  0.14954919 0.15299171 0.27705175 0.13770251]\n",
      "  [0.2827048  0.14954919 0.15299171 0.27705175 0.13770251]\n",
      "  [0.2827048  0.14954919 0.15299171 0.27705175 0.13770251]\n",
      "  [0.2827048  0.14954919 0.15299171 0.27705175 0.13770251]\n",
      "  [0.2827048  0.14954919 0.15299171 0.27705175 0.13770251]\n",
      "  [0.2827048  0.14954919 0.15299171 0.27705175 0.13770251]\n",
      "  [0.2827048  0.14954919 0.15299171 0.27705175 0.13770251]\n",
      "  [0.2827048  0.14954919 0.15299171 0.27705175 0.13770251]\n",
      "  [0.2827048  0.14954919 0.15299171 0.27705175 0.13770251]\n",
      "  [0.2827048  0.14954919 0.15299171 0.27705175 0.13770251]\n",
      "  [0.2827048  0.14954919 0.15299171 0.27705175 0.13770251]\n",
      "  [0.2827048  0.14954919 0.15299171 0.27705175 0.13770251]\n",
      "  [0.2827048  0.14954919 0.15299171 0.27705175 0.13770251]\n",
      "  [0.2827048  0.14954919 0.15299171 0.27705175 0.13770251]]\n",
      "\n",
      " [[0.2799671  0.14450172 0.1541372  0.2792169  0.14217709]\n",
      "  [0.2799674  0.14450164 0.15413709 0.2792169  0.14217697]\n",
      "  [0.27996764 0.144502   0.15413716 0.27921647 0.14217675]\n",
      "  [0.2799676  0.14450172 0.15413705 0.2792168  0.14217682]\n",
      "  [0.27996704 0.14450154 0.15413712 0.27921706 0.14217716]\n",
      "  [0.2799677  0.14450188 0.15413713 0.27921656 0.14217673]\n",
      "  [0.27996743 0.14450176 0.15413715 0.27921677 0.14217691]\n",
      "  [0.27996778 0.14450197 0.15413707 0.27921653 0.14217664]\n",
      "  [0.2799676  0.14450188 0.15413715 0.27921656 0.14217678]\n",
      "  [0.27996922 0.1445026  0.15413699 0.27921554 0.14217566]\n",
      "  [0.27996922 0.1445026  0.15413699 0.27921554 0.14217566]\n",
      "  [0.27996922 0.1445026  0.15413699 0.27921554 0.14217566]\n",
      "  [0.27996922 0.1445026  0.15413699 0.27921554 0.14217566]\n",
      "  [0.27996922 0.1445026  0.15413699 0.27921554 0.14217566]\n",
      "  [0.27996922 0.1445026  0.15413699 0.27921554 0.14217566]\n",
      "  [0.27996922 0.1445026  0.15413699 0.27921554 0.14217566]\n",
      "  [0.27996922 0.1445026  0.15413699 0.27921554 0.14217566]\n",
      "  [0.27996922 0.1445026  0.15413699 0.27921554 0.14217566]\n",
      "  [0.27996922 0.1445026  0.15413699 0.27921554 0.14217566]\n",
      "  [0.27996922 0.1445026  0.15413699 0.27921554 0.14217566]\n",
      "  [0.27996922 0.1445026  0.15413699 0.27921554 0.14217566]\n",
      "  [0.27996922 0.1445026  0.15413699 0.27921554 0.14217566]\n",
      "  [0.27996922 0.1445026  0.15413699 0.27921554 0.14217566]\n",
      "  [0.27996922 0.1445026  0.15413699 0.27921554 0.14217566]\n",
      "  [0.27996922 0.1445026  0.15413699 0.27921554 0.14217566]]\n",
      "\n",
      " [[0.2915954  0.15255745 0.14498758 0.27354696 0.13731256]\n",
      "  [0.2915953  0.15255767 0.14498775 0.2735468  0.1373125 ]\n",
      "  [0.29159516 0.15255716 0.14498754 0.2735473  0.13731286]\n",
      "  [0.29159546 0.15255783 0.14498799 0.27354634 0.13731237]\n",
      "  [0.29159528 0.1525576  0.14498782 0.27354673 0.1373126 ]\n",
      "  [0.29159516 0.15255713 0.14498751 0.27354738 0.1373128 ]\n",
      "  [0.2915955  0.15255764 0.14498773 0.27354667 0.13731249]\n",
      "  [0.291595   0.1525572  0.14498769 0.2735472  0.1373129 ]\n",
      "  [0.29159558 0.15255755 0.14498748 0.27354681 0.1373125 ]\n",
      "  [0.29159722 0.1525588  0.14498751 0.27354527 0.13731125]\n",
      "  [0.29159722 0.1525588  0.14498751 0.27354527 0.13731125]\n",
      "  [0.29159722 0.1525588  0.14498751 0.27354527 0.13731125]\n",
      "  [0.29159722 0.1525588  0.14498751 0.27354527 0.13731125]\n",
      "  [0.29159722 0.1525588  0.14498751 0.27354527 0.13731125]\n",
      "  [0.29159722 0.1525588  0.14498751 0.27354527 0.13731125]\n",
      "  [0.29159722 0.1525588  0.14498751 0.27354527 0.13731125]\n",
      "  [0.29159722 0.1525588  0.14498751 0.27354527 0.13731125]\n",
      "  [0.29159722 0.1525588  0.14498751 0.27354527 0.13731125]\n",
      "  [0.29159722 0.1525588  0.14498751 0.27354527 0.13731125]\n",
      "  [0.29159722 0.1525588  0.14498751 0.27354527 0.13731125]\n",
      "  [0.29159722 0.1525588  0.14498751 0.27354527 0.13731125]\n",
      "  [0.29159722 0.1525588  0.14498751 0.27354527 0.13731125]\n",
      "  [0.29159722 0.1525588  0.14498751 0.27354527 0.13731125]\n",
      "  [0.29159722 0.1525588  0.14498751 0.27354527 0.13731125]\n",
      "  [0.29159722 0.1525588  0.14498751 0.27354527 0.13731125]]\n",
      "\n",
      " [[0.28225243 0.15031448 0.15187916 0.2748077  0.14074625]\n",
      "  [0.2822521  0.15031427 0.15187922 0.27480793 0.14074647]\n",
      "  [0.2822521  0.15031426 0.15187937 0.27480772 0.14074653]\n",
      "  [0.2822523  0.1503144  0.15187928 0.27480757 0.14074641]\n",
      "  [0.2822527  0.15031464 0.1518792  0.27480745 0.14074604]\n",
      "  [0.28225252 0.15031451 0.15187913 0.27480763 0.1407462 ]\n",
      "  [0.28225198 0.15031418 0.15187936 0.2748078  0.14074665]\n",
      "  [0.28225225 0.1503144  0.15187927 0.27480772 0.14074641]\n",
      "  [0.2822521  0.1503142  0.15187924 0.27480793 0.14074655]\n",
      "  [0.2822542  0.15031528 0.15187879 0.27480662 0.14074515]\n",
      "  [0.2822542  0.15031528 0.15187879 0.27480662 0.14074515]\n",
      "  [0.2822542  0.15031528 0.15187879 0.27480662 0.14074515]\n",
      "  [0.2822542  0.15031528 0.15187879 0.27480662 0.14074515]\n",
      "  [0.2822542  0.15031528 0.15187879 0.27480662 0.14074515]\n",
      "  [0.2822542  0.15031528 0.15187879 0.27480662 0.14074515]\n",
      "  [0.2822542  0.15031528 0.15187879 0.27480662 0.14074515]\n",
      "  [0.2822542  0.15031528 0.15187879 0.27480662 0.14074515]\n",
      "  [0.2822542  0.15031528 0.15187879 0.27480662 0.14074515]\n",
      "  [0.2822542  0.15031528 0.15187879 0.27480662 0.14074515]\n",
      "  [0.2822542  0.15031528 0.15187879 0.27480662 0.14074515]\n",
      "  [0.2822542  0.15031528 0.15187879 0.27480662 0.14074515]\n",
      "  [0.2822542  0.15031528 0.15187879 0.27480662 0.14074515]\n",
      "  [0.2822542  0.15031528 0.15187879 0.27480662 0.14074515]\n",
      "  [0.2822542  0.15031528 0.15187879 0.27480662 0.14074515]\n",
      "  [0.2822542  0.15031528 0.15187879 0.27480662 0.14074515]]]\n",
      "\n",
      "Embeddings for Task B (Sentiment):\n",
      "[[0.5058014  0.49419862]\n",
      " [0.49383995 0.5061601 ]\n",
      " [0.49792734 0.5020727 ]\n",
      " [0.50833374 0.4916663 ]]\n",
      "\n",
      "Embeddings for the first input sentence (Task A):\n",
      "[[0.28270373 0.14954853 0.15299174 0.27705252 0.1377034 ]\n",
      " [0.2827034  0.14954832 0.15299176 0.27705282 0.13770373]\n",
      " [0.28270358 0.14954841 0.15299182 0.27705264 0.1377036 ]\n",
      " [0.2827036  0.14954856 0.15299189 0.2770525  0.13770348]\n",
      " [0.28270352 0.1495485  0.15299183 0.27705264 0.13770358]\n",
      " [0.2827037  0.1495485  0.15299173 0.27705264 0.13770345]\n",
      " [0.28270346 0.14954846 0.1529918  0.27705267 0.13770363]\n",
      " [0.2827048  0.14954919 0.15299171 0.27705175 0.13770251]\n",
      " [0.2827048  0.14954919 0.15299171 0.27705175 0.13770251]\n",
      " [0.2827048  0.14954919 0.15299171 0.27705175 0.13770251]\n",
      " [0.2827048  0.14954919 0.15299171 0.27705175 0.13770251]\n",
      " [0.2827048  0.14954919 0.15299171 0.27705175 0.13770251]\n",
      " [0.2827048  0.14954919 0.15299171 0.27705175 0.13770251]\n",
      " [0.2827048  0.14954919 0.15299171 0.27705175 0.13770251]\n",
      " [0.2827048  0.14954919 0.15299171 0.27705175 0.13770251]\n",
      " [0.2827048  0.14954919 0.15299171 0.27705175 0.13770251]\n",
      " [0.2827048  0.14954919 0.15299171 0.27705175 0.13770251]\n",
      " [0.2827048  0.14954919 0.15299171 0.27705175 0.13770251]\n",
      " [0.2827048  0.14954919 0.15299171 0.27705175 0.13770251]\n",
      " [0.2827048  0.14954919 0.15299171 0.27705175 0.13770251]\n",
      " [0.2827048  0.14954919 0.15299171 0.27705175 0.13770251]\n",
      " [0.2827048  0.14954919 0.15299171 0.27705175 0.13770251]\n",
      " [0.2827048  0.14954919 0.15299171 0.27705175 0.13770251]\n",
      " [0.2827048  0.14954919 0.15299171 0.27705175 0.13770251]\n",
      " [0.2827048  0.14954919 0.15299171 0.27705175 0.13770251]]\n",
      "\n",
      "Embeddings for the first input sentence (Task B):\n",
      "[0.5058014  0.49419862]\n"
     ]
    }
   ],
   "source": [
    "# Show the embeddings\n",
    "print(\"Embeddings for Task A (NER):\")\n",
    "print(task_a_embeddings)\n",
    "\n",
    "print(\"\\nEmbeddings for Task B (Sentiment):\")\n",
    "print(task_b_embeddings)\n",
    "\n",
    "# If you want to see the embeddings for a specific input, you can index into the predictions\n",
    "# For example, embeddings for the first input sentence\n",
    "print(\"\\nEmbeddings for the first input sentence (Task A):\")\n",
    "print(task_a_embeddings[0])\n",
    "\n",
    "print(\"\\nEmbeddings for the first input sentence (Task B):\")\n",
    "print(task_b_embeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59a80b8",
   "metadata": {},
   "source": [
    "### Task 4: Layer-wise Learning Rate Implementation\n",
    "\n",
    "#### The custom learning rate schedule class in TensorFlow is designed to dynamically adjust the learning rate during training. We start by initializing it with a base learning rate, a decay rate, and the number of layers. The __call__ method is then used to calculate the learning rate at each step by dividing the base learning rate by one plus the decay rate times the current step. This makes sure that as training progresses, the learning rate gradually decreases, helping the model converge better. We also have a get_config method to make the schedule serializable, returning the configuration parameters. This custom schedule helps us fine-tune our model's training process more effectively.\n",
    "\n",
    "### Code (in custom_lr_schedule.py):\n",
    "```python\n",
    "class CustomLearningRateSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, base_learning_rate, decay_rate, num_layers):\n",
    "        super(CustomLearningRateSchedule, self).__init__()\n",
    "        self.base_learning_rate = base_learning_rate\n",
    "        self.decay_rate = decay_rate\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    def __call__(self, step):\n",
    "        return self.base_learning_rate / (1 + self.decay_rate * tf.cast(step, tf.float32))\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {\n",
    "            'base_learning_rate': self.base_learning_rate,\n",
    "            'decay_rate': self.decay_rate,\n",
    "            'num_layers': self.num_layers\n",
    "        }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32d72505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 25)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, 25, 128)              3968      ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (Mu  (None, 25, 128)              131968    ['embedding_1[0][0]',         \n",
      " ltiHeadAttention)                                                   'embedding_1[0][0]']         \n",
      "                                                                                                  \n",
      " layer_normalization_1 (Lay  (None, 25, 128)              256       ['multi_head_attention_1[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 25, 128)              16512     ['layer_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 25, 128)              16512     ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1  (None, 128)                  0         ['dense_4[0][0]']             \n",
      "  (GlobalAveragePooling1D)                                                                        \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 128)                  16512     ['global_average_pooling1d_1[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " task_a (TimeDistributed)    (None, 25, 5)                645       ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      " task_b (Dense)              (None, 2)                    258       ['dense_6[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 186631 (729.03 KB)\n",
      "Trainable params: 186631 (729.03 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Applying the custom learning rate schedule\n",
    "base_learning_rate = 0.001\n",
    "decay_rate = 0.01\n",
    "num_layers = 10\n",
    "learning_rate_schedule = CustomLearningRateSchedule(base_learning_rate, decay_rate, num_layers)\n",
    "optimizer = Adam(learning_rate=learning_rate_schedule)\n",
    "\n",
    "multi_task_model.compile(optimizer=optimizer, loss={'task_a': 'sparse_categorical_crossentropy', 'task_b': 'sparse_categorical_crossentropy'}, metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "multi_task_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb357fe",
   "metadata": {},
   "source": [
    "### Embeddings returned by the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "984ab697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of padded_sequences: (4, 25), Data type: int32\n",
      "Shape of task_a_labels: (4, 25), Data type: int32\n",
      "Shape of task_b_labels: (4,), Data type: int32\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.0824 - task_a_loss: 0.1107 - task_b_loss: 0.9717 - task_a_accuracy: 0.9800 - task_b_accuracy: 0.5000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7635 - task_a_loss: 0.1042 - task_b_loss: 0.6593 - task_a_accuracy: 0.9800 - task_b_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8676 - task_a_loss: 0.1020 - task_b_loss: 0.7656 - task_a_accuracy: 0.9800 - task_b_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9068 - task_a_loss: 0.1030 - task_b_loss: 0.8037 - task_a_accuracy: 0.9800 - task_b_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7687 - task_a_loss: 0.1046 - task_b_loss: 0.6642 - task_a_accuracy: 0.9800 - task_b_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7456 - task_a_loss: 0.1052 - task_b_loss: 0.6404 - task_a_accuracy: 0.9800 - task_b_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8013 - task_a_loss: 0.1047 - task_b_loss: 0.6966 - task_a_accuracy: 0.9800 - task_b_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7743 - task_a_loss: 0.1035 - task_b_loss: 0.6708 - task_a_accuracy: 0.9800 - task_b_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7093 - task_a_loss: 0.1022 - task_b_loss: 0.6071 - task_a_accuracy: 0.9800 - task_b_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7072 - task_a_loss: 0.1013 - task_b_loss: 0.6059 - task_a_accuracy: 0.9800 - task_b_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7324 - task_a_loss: 0.1008 - task_b_loss: 0.6316 - task_a_accuracy: 0.9800 - task_b_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7108 - task_a_loss: 0.1006 - task_b_loss: 0.6102 - task_a_accuracy: 0.9800 - task_b_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6648 - task_a_loss: 0.1007 - task_b_loss: 0.5642 - task_a_accuracy: 0.9800 - task_b_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6509 - task_a_loss: 0.1008 - task_b_loss: 0.5501 - task_a_accuracy: 0.9800 - task_b_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6573 - task_a_loss: 0.1008 - task_b_loss: 0.5565 - task_a_accuracy: 0.9800 - task_b_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6372 - task_a_loss: 0.1007 - task_b_loss: 0.5365 - task_a_accuracy: 0.9800 - task_b_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5945 - task_a_loss: 0.1005 - task_b_loss: 0.4940 - task_a_accuracy: 0.9800 - task_b_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5659 - task_a_loss: 0.1001 - task_b_loss: 0.4658 - task_a_accuracy: 0.9800 - task_b_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5540 - task_a_loss: 0.0996 - task_b_loss: 0.4544 - task_a_accuracy: 0.9800 - task_b_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5259 - task_a_loss: 0.0989 - task_b_loss: 0.4270 - task_a_accuracy: 0.9800 - task_b_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4769 - task_a_loss: 0.0982 - task_b_loss: 0.3787 - task_a_accuracy: 0.9800 - task_b_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4353 - task_a_loss: 0.0974 - task_b_loss: 0.3378 - task_a_accuracy: 0.9800 - task_b_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4060 - task_a_loss: 0.0967 - task_b_loss: 0.3093 - task_a_accuracy: 0.9800 - task_b_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3673 - task_a_loss: 0.0961 - task_b_loss: 0.2712 - task_a_accuracy: 0.9800 - task_b_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3169 - task_a_loss: 0.0956 - task_b_loss: 0.2214 - task_a_accuracy: 0.9800 - task_b_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2742 - task_a_loss: 0.0950 - task_b_loss: 0.1792 - task_a_accuracy: 0.9800 - task_b_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2407 - task_a_loss: 0.0942 - task_b_loss: 0.1465 - task_a_accuracy: 0.9800 - task_b_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2073 - task_a_loss: 0.0932 - task_b_loss: 0.1140 - task_a_accuracy: 0.9800 - task_b_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1738 - task_a_loss: 0.0922 - task_b_loss: 0.0816 - task_a_accuracy: 0.9800 - task_b_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1470 - task_a_loss: 0.0910 - task_b_loss: 0.0560 - task_a_accuracy: 0.9800 - task_b_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Predictions for Task A (NER): [[[9.69794631e-01 2.94138286e-02 1.77745038e-04 1.67104736e-04\n",
      "   4.46671183e-04]\n",
      "  [9.69783187e-01 2.94256043e-02 1.77686859e-04 1.67015300e-04\n",
      "   4.46528778e-04]\n",
      "  [9.69785511e-01 2.94231623e-02 1.77693553e-04 1.67029706e-04\n",
      "   4.46548365e-04]\n",
      "  [9.69771266e-01 2.94377878e-02 1.77641807e-04 1.66935381e-04\n",
      "   4.46410879e-04]\n",
      "  [9.69795287e-01 2.94132046e-02 1.77738897e-04 1.67101651e-04\n",
      "   4.46660415e-04]\n",
      "  [9.69797432e-01 2.94111241e-02 1.77733178e-04 1.67104576e-04\n",
      "   4.46655642e-04]\n",
      "  [9.69807744e-01 2.94004697e-02 1.77791531e-04 1.67190199e-04\n",
      "   4.46795661e-04]\n",
      "  [9.69674349e-01 2.95369700e-02 1.77205264e-04 1.66229089e-04\n",
      "   4.45313926e-04]\n",
      "  [9.69674349e-01 2.95369700e-02 1.77205264e-04 1.66229089e-04\n",
      "   4.45313926e-04]\n",
      "  [9.69674349e-01 2.95369700e-02 1.77205264e-04 1.66229089e-04\n",
      "   4.45313926e-04]\n",
      "  [9.69674349e-01 2.95369700e-02 1.77205264e-04 1.66229089e-04\n",
      "   4.45313926e-04]\n",
      "  [9.69674349e-01 2.95369700e-02 1.77205264e-04 1.66229089e-04\n",
      "   4.45313926e-04]\n",
      "  [9.69674349e-01 2.95369700e-02 1.77205264e-04 1.66229089e-04\n",
      "   4.45313926e-04]\n",
      "  [9.69674349e-01 2.95369700e-02 1.77205264e-04 1.66229089e-04\n",
      "   4.45313926e-04]\n",
      "  [9.69674349e-01 2.95369700e-02 1.77205264e-04 1.66229089e-04\n",
      "   4.45313926e-04]\n",
      "  [9.69674349e-01 2.95369700e-02 1.77205264e-04 1.66229089e-04\n",
      "   4.45313926e-04]\n",
      "  [9.69674349e-01 2.95369700e-02 1.77205264e-04 1.66229089e-04\n",
      "   4.45313926e-04]\n",
      "  [9.69674349e-01 2.95369700e-02 1.77205264e-04 1.66229089e-04\n",
      "   4.45313926e-04]\n",
      "  [9.69674349e-01 2.95369700e-02 1.77205264e-04 1.66229089e-04\n",
      "   4.45313926e-04]\n",
      "  [9.69674349e-01 2.95369700e-02 1.77205264e-04 1.66229089e-04\n",
      "   4.45313926e-04]\n",
      "  [9.69674349e-01 2.95369700e-02 1.77205264e-04 1.66229089e-04\n",
      "   4.45313926e-04]\n",
      "  [9.69674349e-01 2.95369700e-02 1.77205264e-04 1.66229089e-04\n",
      "   4.45313926e-04]\n",
      "  [9.69674349e-01 2.95369700e-02 1.77205264e-04 1.66229089e-04\n",
      "   4.45313926e-04]\n",
      "  [9.69674349e-01 2.95369700e-02 1.77205264e-04 1.66229089e-04\n",
      "   4.45313926e-04]\n",
      "  [9.69674349e-01 2.95369700e-02 1.77205264e-04 1.66229089e-04\n",
      "   4.45313926e-04]]\n",
      "\n",
      " [[9.84580457e-01 1.38606960e-02 2.74346676e-04 4.59490228e-04\n",
      "   8.25034513e-04]\n",
      "  [9.84593093e-01 1.38461422e-02 2.74649909e-04 4.60291660e-04\n",
      "   8.25786556e-04]\n",
      "  [9.84604061e-01 1.38334744e-02 2.74922117e-04 4.61019052e-04\n",
      "   8.26497446e-04]\n",
      "  [9.84583616e-01 1.38570126e-02 2.74418475e-04 4.59675066e-04\n",
      "   8.25189403e-04]\n",
      "  [9.84592736e-01 1.38465865e-02 2.74640915e-04 4.60268231e-04\n",
      "   8.25766241e-04]\n",
      "  [9.84580159e-01 1.38610946e-02 2.74334248e-04 4.59453440e-04\n",
      "   8.24984279e-04]\n",
      "  [9.84593332e-01 1.38458684e-02 2.74652877e-04 4.60296171e-04\n",
      "   8.25780851e-04]\n",
      "  [9.84600008e-01 1.38382269e-02 2.74819817e-04 4.60745970e-04\n",
      "   8.26231146e-04]\n",
      "  [9.84588683e-01 1.38511257e-02 2.74549180e-04 4.60028532e-04\n",
      "   8.25552619e-04]\n",
      "  [9.84663904e-01 1.37646189e-02 2.76384206e-04 4.64884302e-04\n",
      "   8.30133271e-04]\n",
      "  [9.84663904e-01 1.37646189e-02 2.76384206e-04 4.64884302e-04\n",
      "   8.30133271e-04]\n",
      "  [9.84663904e-01 1.37646189e-02 2.76384206e-04 4.64884302e-04\n",
      "   8.30133271e-04]\n",
      "  [9.84663904e-01 1.37646189e-02 2.76384206e-04 4.64884302e-04\n",
      "   8.30133271e-04]\n",
      "  [9.84663904e-01 1.37646189e-02 2.76384206e-04 4.64884302e-04\n",
      "   8.30133271e-04]\n",
      "  [9.84663904e-01 1.37646189e-02 2.76384206e-04 4.64884302e-04\n",
      "   8.30133271e-04]\n",
      "  [9.84663904e-01 1.37646189e-02 2.76384206e-04 4.64884302e-04\n",
      "   8.30133271e-04]\n",
      "  [9.84663904e-01 1.37646189e-02 2.76384206e-04 4.64884302e-04\n",
      "   8.30133271e-04]\n",
      "  [9.84663904e-01 1.37646189e-02 2.76384206e-04 4.64884302e-04\n",
      "   8.30133271e-04]\n",
      "  [9.84663904e-01 1.37646189e-02 2.76384206e-04 4.64884302e-04\n",
      "   8.30133271e-04]\n",
      "  [9.84663904e-01 1.37646189e-02 2.76384206e-04 4.64884302e-04\n",
      "   8.30133271e-04]\n",
      "  [9.84663904e-01 1.37646189e-02 2.76384206e-04 4.64884302e-04\n",
      "   8.30133271e-04]\n",
      "  [9.84663904e-01 1.37646189e-02 2.76384206e-04 4.64884302e-04\n",
      "   8.30133271e-04]\n",
      "  [9.84663904e-01 1.37646189e-02 2.76384206e-04 4.64884302e-04\n",
      "   8.30133271e-04]\n",
      "  [9.84663904e-01 1.37646189e-02 2.76384206e-04 4.64884302e-04\n",
      "   8.30133271e-04]\n",
      "  [9.84663904e-01 1.37646189e-02 2.76384206e-04 4.64884302e-04\n",
      "   8.30133271e-04]]\n",
      "\n",
      " [[9.59075749e-01 4.00948003e-02 1.86140052e-04 1.59331583e-04\n",
      "   4.83952637e-04]\n",
      "  [9.59006667e-01 4.01643664e-02 1.86028512e-04 1.59197400e-04\n",
      "   4.83655254e-04]\n",
      "  [9.59025681e-01 4.01454456e-02 1.86058081e-04 1.59233488e-04\n",
      "   4.83734708e-04]\n",
      "  [9.58986402e-01 4.01848927e-02 1.85991754e-04 1.59156232e-04\n",
      "   4.83559008e-04]\n",
      "  [9.59016860e-01 4.01541442e-02 1.86023026e-04 1.59208954e-04\n",
      "   4.83656448e-04]\n",
      "  [9.59080577e-01 4.00899313e-02 1.86142759e-04 1.59339674e-04\n",
      "   4.83963173e-04]\n",
      "  [9.59059000e-01 4.01117913e-02 1.86110512e-04 1.59297793e-04\n",
      "   4.83876793e-04]\n",
      "  [9.59035218e-01 4.01358046e-02 1.86063480e-04 1.59248288e-04\n",
      "   4.83756623e-04]\n",
      "  [9.59007680e-01 4.01635021e-02 1.86019999e-04 1.59195115e-04\n",
      "   4.83639626e-04]\n",
      "  [9.58681703e-01 4.04919498e-02 1.85499797e-04 1.58570780e-04\n",
      "   4.82245930e-04]\n",
      "  [9.58681703e-01 4.04919498e-02 1.85499797e-04 1.58570780e-04\n",
      "   4.82245930e-04]\n",
      "  [9.58681703e-01 4.04919498e-02 1.85499797e-04 1.58570780e-04\n",
      "   4.82245930e-04]\n",
      "  [9.58681703e-01 4.04919498e-02 1.85499797e-04 1.58570780e-04\n",
      "   4.82245930e-04]\n",
      "  [9.58681703e-01 4.04919498e-02 1.85499797e-04 1.58570780e-04\n",
      "   4.82245930e-04]\n",
      "  [9.58681703e-01 4.04919498e-02 1.85499797e-04 1.58570780e-04\n",
      "   4.82245930e-04]\n",
      "  [9.58681703e-01 4.04919498e-02 1.85499797e-04 1.58570780e-04\n",
      "   4.82245930e-04]\n",
      "  [9.58681703e-01 4.04919498e-02 1.85499797e-04 1.58570780e-04\n",
      "   4.82245930e-04]\n",
      "  [9.58681703e-01 4.04919498e-02 1.85499797e-04 1.58570780e-04\n",
      "   4.82245930e-04]\n",
      "  [9.58681703e-01 4.04919498e-02 1.85499797e-04 1.58570780e-04\n",
      "   4.82245930e-04]\n",
      "  [9.58681703e-01 4.04919498e-02 1.85499797e-04 1.58570780e-04\n",
      "   4.82245930e-04]\n",
      "  [9.58681703e-01 4.04919498e-02 1.85499797e-04 1.58570780e-04\n",
      "   4.82245930e-04]\n",
      "  [9.58681703e-01 4.04919498e-02 1.85499797e-04 1.58570780e-04\n",
      "   4.82245930e-04]\n",
      "  [9.58681703e-01 4.04919498e-02 1.85499797e-04 1.58570780e-04\n",
      "   4.82245930e-04]\n",
      "  [9.58681703e-01 4.04919498e-02 1.85499797e-04 1.58570780e-04\n",
      "   4.82245930e-04]\n",
      "  [9.58681703e-01 4.04919498e-02 1.85499797e-04 1.58570780e-04\n",
      "   4.82245930e-04]]\n",
      "\n",
      " [[9.83420551e-01 1.50978267e-02 2.71138764e-04 4.16430004e-04\n",
      "   7.94074789e-04]\n",
      "  [9.83440876e-01 1.50752254e-02 2.71534082e-04 4.17361036e-04\n",
      "   7.95001630e-04]\n",
      "  [9.83435094e-01 1.50816161e-02 2.71427649e-04 4.17112053e-04\n",
      "   7.94767577e-04]\n",
      "  [9.83433485e-01 1.50835095e-02 2.71389930e-04 4.17021889e-04\n",
      "   7.94665539e-04]\n",
      "  [9.83427942e-01 1.50897773e-02 2.71263154e-04 4.16715222e-04\n",
      "   7.94314023e-04]\n",
      "  [9.83416319e-01 1.51026566e-02 2.71039346e-04 4.16188006e-04\n",
      "   7.93792249e-04]\n",
      "  [9.83420789e-01 1.50974123e-02 2.71150202e-04 4.16459341e-04\n",
      "   7.94116582e-04]\n",
      "  [9.83432233e-01 1.50847500e-02 2.71372759e-04 4.16982948e-04\n",
      "   7.94639462e-04]\n",
      "  [9.83435690e-01 1.50811067e-02 2.71431956e-04 4.17119649e-04\n",
      "   7.94762396e-04]\n",
      "  [9.83505666e-01 1.50025478e-02 2.72886333e-04 4.20573109e-04\n",
      "   7.98363995e-04]\n",
      "  [9.83505666e-01 1.50025478e-02 2.72886333e-04 4.20573109e-04\n",
      "   7.98363995e-04]\n",
      "  [9.83505666e-01 1.50025478e-02 2.72886333e-04 4.20573109e-04\n",
      "   7.98363995e-04]\n",
      "  [9.83505666e-01 1.50025478e-02 2.72886333e-04 4.20573109e-04\n",
      "   7.98363995e-04]\n",
      "  [9.83505666e-01 1.50025478e-02 2.72886333e-04 4.20573109e-04\n",
      "   7.98363995e-04]\n",
      "  [9.83505666e-01 1.50025478e-02 2.72886333e-04 4.20573109e-04\n",
      "   7.98363995e-04]\n",
      "  [9.83505666e-01 1.50025478e-02 2.72886333e-04 4.20573109e-04\n",
      "   7.98363995e-04]\n",
      "  [9.83505666e-01 1.50025478e-02 2.72886333e-04 4.20573109e-04\n",
      "   7.98363995e-04]\n",
      "  [9.83505666e-01 1.50025478e-02 2.72886333e-04 4.20573109e-04\n",
      "   7.98363995e-04]\n",
      "  [9.83505666e-01 1.50025478e-02 2.72886333e-04 4.20573109e-04\n",
      "   7.98363995e-04]\n",
      "  [9.83505666e-01 1.50025478e-02 2.72886333e-04 4.20573109e-04\n",
      "   7.98363995e-04]\n",
      "  [9.83505666e-01 1.50025478e-02 2.72886333e-04 4.20573109e-04\n",
      "   7.98363995e-04]\n",
      "  [9.83505666e-01 1.50025478e-02 2.72886333e-04 4.20573109e-04\n",
      "   7.98363995e-04]\n",
      "  [9.83505666e-01 1.50025478e-02 2.72886333e-04 4.20573109e-04\n",
      "   7.98363995e-04]\n",
      "  [9.83505666e-01 1.50025478e-02 2.72886333e-04 4.20573109e-04\n",
      "   7.98363995e-04]\n",
      "  [9.83505666e-01 1.50025478e-02 2.72886333e-04 4.20573109e-04\n",
      "   7.98363646e-04]]]\n",
      "Predictions for Task B (Sentiment): [[0.05021495 0.94978505]\n",
      " [0.9698467  0.03015328]\n",
      " [0.01710361 0.9828964 ]\n",
      " [0.9460839  0.05391614]]\n"
     ]
    }
   ],
   "source": [
    "# Ensure shapes and data types are correct\n",
    "print(f\"Shape of padded_sequences: {padded_sequences.shape}, Data type: {padded_sequences.dtype}\")\n",
    "print(f\"Shape of task_a_labels: {task_a_labels.shape}, Data type: {task_a_labels.dtype}\")\n",
    "print(f\"Shape of task_b_labels: {task_b_labels.shape}, Data type: {task_b_labels.dtype}\")\n",
    "\n",
    "# Train the model\n",
    "multi_task_model.fit(padded_sequences, {'task_a': task_a_labels, 'task_b': task_b_labels}, epochs=30)\n",
    "\n",
    "# Test the model\n",
    "predictions = multi_task_model.predict(padded_sequences)\n",
    "print(\"Predictions for Task A (NER):\", predictions[0])\n",
    "print(\"Predictions for Task B (Sentiment):\", predictions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9842c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
